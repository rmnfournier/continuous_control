{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Reacher \n",
    "\n",
    "In this short Notebook, I will show how my implementation of Deep Deterministic Policy Gradient (DDPG) manages to solve Unity's Reacher environment. This project was carried out as part as Udacity's DRL nanodegree and some of the code are inspired from examples of the course.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by launching the environment. \n",
    "\n",
    "1) Download the environment \n",
    "Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Linux.zip)\n",
    "Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher.app.zip)\n",
    "Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Windows_x86.zip)\n",
    "Windows (64-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Windows_x86_64.zip)\n",
    "\n",
    "2) Indicate the location of the following file : \n",
    "Mac: \"path/to/Reacher.app\"\n",
    "\n",
    "Windows (x86): \"path/to/Reacher_Windows_x86/Reacher.exe\"\n",
    "\n",
    "Windows (x86_64): \"path/to/Reacher_Windows_x86_64/Reacher.exe\"\n",
    "\n",
    "Linux (x86): \"path/to/Reacher_Linux/Reacher.x86\"\n",
    "\n",
    "Linux (x86_64): \"path/to/Reacher_Linux/Reacher.x86_64\"\n",
    "\n",
    "Linux (x86, headless): \"path/to/Reacher_Linux_NoVis/Reacher.x86\"\n",
    "\n",
    "Linux (x86_64, headless): \"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"\n",
    "\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "#Indicate the environment location in the location variable\n",
    "location = '../Project/Reacher_Linux/Reacher.x86_64'\n",
    "#no_graphics=True disables the graphics and speeds up the training\n",
    "env = UnityEnvironment(file_name=location,no_graphics=False)\n",
    "\n",
    "# Start the Brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's have a look at the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note : skip this part if you don't want to train the agent, *\n",
    "The agent and the descriptions of the neural networks are located in ddpg_agent.py and model.py respectively. Here, we just create one agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Actor and Critic Policy\n",
    "from ddpg_agent import Agent\n",
    "#Create an agent\n",
    "agent = Agent(state_size=33, action_size=4, random_seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start the training. We will output the average score over the last 5 episodes and the one over the 100 last ones. The environment is considered solved when the agent reaches an average score of 30 over the 100 last episodes. We will collect experience from 20 different agents, but only train one actor and one critic. Each agent will use the same weights for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.conda/envs/DRL/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5\tAverage Score: 0.745 last episodes: 0.74\t Average over 100 last episodes :0.74\n",
      "Episode 10\tAverage Score: 1.355 last episodes: 1.35\t Average over 100 last episodes :1.05\n",
      "Episode 15\tAverage Score: 2.465 last episodes: 2.46\t Average over 100 last episodes :1.52\n",
      "Episode 20\tAverage Score: 6.995 last episodes: 6.99\t Average over 100 last episodes :2.89\n",
      "Episode 25\tAverage Score: 15.36 last episodes: 15.36\t Average over 100 last episodes :5.38\n",
      "Episode 30\tAverage Score: 19.29 last episodes: 19.29\t Average over 100 last episodes :7.70\n",
      "Episode 35\tAverage Score: 21.92 last episodes: 21.92\t Average over 100 last episodes :9.73\n",
      "Episode 40\tAverage Score: 27.68 last episodes: 27.68\t Average over 100 last episodes :11.97\n",
      "Episode 45\tAverage Score: 33.79 last episodes: 33.79\t Average over 100 last episodes :14.40\n",
      "Episode 50\tAverage Score: 36.62 last episodes: 36.62\t Average over 100 last episodes :16.62\n",
      "Episode 55\tAverage Score: 38.88 last episodes: 38.88\t Average over 100 last episodes :18.65\n",
      "Episode 60\tAverage Score: 39.08 last episodes: 39.08\t Average over 100 last episodes :20.35\n",
      "Episode 65\tAverage Score: 35.75 last episodes: 35.75\t Average over 100 last episodes :21.53\n",
      "Episode 70\tAverage Score: 38.07 last episodes: 38.07\t Average over 100 last episodes :22.71\n",
      "Episode 75\tAverage Score: 38.57 last episodes: 38.57\t Average over 100 last episodes :23.77\n",
      "Episode 80\tAverage Score: 38.24 last episodes: 38.24\t Average over 100 last episodes :24.68\n",
      "Episode 85\tAverage Score: 37.31 last episodes: 37.31\t Average over 100 last episodes :25.42\n",
      "Episode 90\tAverage Score: 38.11 last episodes: 38.11\t Average over 100 last episodes :26.12\n",
      "Episode 95\tAverage Score: 38.41 last episodes: 38.41\t Average over 100 last episodes :26.77\n",
      "Episode 100\tAverage Score: 37.18 last episodes: 37.18\t Average over 100 last episodes :27.29\n",
      "Episode 105\tAverage Score: 35.94 last episodes: 35.94\t Average over 100 last episodes :29.05\n",
      "Episode 108\tAverage Score over 5 last episodes: 36.94\t Average over 100 last episodes :30.15Environment Solved !\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ddpg(n_episodes=550, print_every=5):\n",
    "    scores_last_episodes = deque(maxlen=print_every)\n",
    "    scores_target = deque(maxlen=100)\n",
    "    my_scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        agent.reset()                                          #Reset the agent \n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        while True:\n",
    "            actions = agent.act(states)              # select an action (for each agent)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to the environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            agent.step(states,actions,rewards,next_states,dones) #Memorize and learn\n",
    "            scores += env_info.rewards                        # update the score (for each agent)\n",
    "            states = next_states                               # roll over states to next time step            \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        score=np.mean(scores)   \n",
    "        scores_last_episodes.append(score)\n",
    "        scores_target.append(score)\n",
    "        my_scores.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score over 5 last episodes: {:.2f}\\t Average over 100 last episodes :{:.2f}'.format(i_episode, np.mean(scores_last_episodes),np.mean(scores_target)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_last_episodes)))\n",
    "        if(np.mean(scores_target)>30):\n",
    "            print('Environment Solved !')\n",
    "            break\n",
    "        \n",
    "    return my_scores\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "scores = ddpg()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's watch our agent !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.conda/envs/DRL/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        #agent.reset()\n",
    "scores = np.zeros(num_agents)         # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states,True)              # select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to the environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    agent.step(states,actions,rewards,next_states,dones) #Memorize and learn\n",
    "    scores += env_info.rewards                        # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step            \n",
    "    if np.any(dones):\n",
    "        break \n",
    "print(np.mean(scores))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the critic\n",
    "torch.save(agent.critic_local.state_dict(), \"critic.pth\")\n",
    "#Save the actor\n",
    "torch.save(agent.actor_local.state_dict(),\"actor.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and watch\n",
    "agent.critic_local.load_state_dict(torch.load(\"critic.pth\"))\n",
    "agent.actor_local.load_state_dict(torch.load(\"actor.pth\"))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        #agent.reset()\n",
    "scores = np.zeros(num_agents)         # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states,True)              # select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to the environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    agent.step(states,actions,rewards,next_states,dones) #Memorize and learn\n",
    "    scores += env_info.rewards                        # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step            \n",
    "    if np.any(dones):\n",
    "        break \n",
    "print(np.mean(scores))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
